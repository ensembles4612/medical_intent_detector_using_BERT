{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "medical_intent_detector_Using_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "be56de9babe442a4811d85b3339548aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a8e53b37b054446eb76fe87abbddf460",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cee66c2d4b384d7a8b7e946718706f71",
              "IPY_MODEL_b81b76652a25465c8bcfbadba860cf79"
            ]
          }
        },
        "a8e53b37b054446eb76fe87abbddf460": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cee66c2d4b384d7a8b7e946718706f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_671bcb82972a4412a16db716011f17a8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aa96b8556db34c94b9e40474c2381e2f"
          }
        },
        "b81b76652a25465c8bcfbadba860cf79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c38251a78d434a73a6dab64dafcad531",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 806kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8fb32ff00d84494182a9c075983edf2c"
          }
        },
        "671bcb82972a4412a16db716011f17a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aa96b8556db34c94b9e40474c2381e2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c38251a78d434a73a6dab64dafcad531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8fb32ff00d84494182a9c075983edf2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b9d2f88b57246cf96e9a6c2c89ab718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f9be3136155b4142a063643b614b0dd1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d30bd8a5f8ec48859cd6a0060adf8413",
              "IPY_MODEL_048c8b900b2c476cb650e19e2ef91f48"
            ]
          }
        },
        "f9be3136155b4142a063643b614b0dd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d30bd8a5f8ec48859cd6a0060adf8413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_17e5c0b7d44f45c8b790243b90559409",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1bf16755fa3e4a2a82b89b3b3de44b85"
          }
        },
        "048c8b900b2c476cb650e19e2ef91f48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6dc92dc6a3a746c2b71fa7376451325e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.39kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be3a7b235c7a4a4399a10dd783abc5ca"
          }
        },
        "17e5c0b7d44f45c8b790243b90559409": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1bf16755fa3e4a2a82b89b3b3de44b85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6dc92dc6a3a746c2b71fa7376451325e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be3a7b235c7a4a4399a10dd783abc5ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d5059f5a143464594775b110e1c7ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2a9bda2c09524a87bbd15684e89d799d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2e6558cce2fe490eac8a1d3515a50f6c",
              "IPY_MODEL_5f9a469c8723465aafc26e8a19513cd8"
            ]
          }
        },
        "2a9bda2c09524a87bbd15684e89d799d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e6558cce2fe490eac8a1d3515a50f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d913a3797b7c4265936a9c7804947049",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4bee615ac43d42e984797361b9b3fa9f"
          }
        },
        "5f9a469c8723465aafc26e8a19513cd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_de947603ca6c4156b0c4a81f5a9d4bb1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:09&lt;00:00, 46.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d334b6fdec9409b902289c6045f50d1"
          }
        },
        "d913a3797b7c4265936a9c7804947049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4bee615ac43d42e984797361b9b3fa9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de947603ca6c4156b0c4a81f5a9d4bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d334b6fdec9409b902289c6045f50d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K29jSydZAEw4"
      },
      "source": [
        "## **Project Object:** \r\n",
        "\r\n",
        "To build a detecting tool classifying the text of a person's description of their medical symptom to the correct category(intent), which can be used in applications such as a medical chatbot. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84LM1QjCR-t8"
      },
      "source": [
        "## 1. GPU Setup in Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jRS5iG1J88a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "debf1a6f-114f-4761-bf23-a3def3a50dda"
      },
      "source": [
        "# A GPU can be added by going to the menu and selecting: Edit ü°í Notebook Settings ü°í Hardware accelerator ü°í (GPU)\n",
        "# confirm the GPU is detected:\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d87pSEBuQ35E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bed4a20c-d66c-4b60-b926-f0e69015163c"
      },
      "source": [
        "# In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device\n",
        "\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y53rC04VUd6_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti2TzCHpU9Xq"
      },
      "source": [
        "## 2. Load and analyze data\r\n",
        "\r\n",
        "The dataset used is from kaggle: https://www.kaggle.com/paultimothymooney/medical-speech-transcription-and-intent\r\n",
        "\r\n",
        "This data contains thousands of audio utterances and corresponding transcriptions for common medical symptoms like ‚Äúknee pain‚Äù or ‚Äúheadache‚Äù. Only the transcriptions are used in this project.\r\n",
        "\r\n",
        "We can see from below:\r\n",
        "* column \"phrase\" contains transcriptions describing a person's certain medical symptoms\r\n",
        "* column \"promp\" contains their corresponding intents (25 intents in total)\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTw2Dkk3VA8j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "outputId": "ae13df70-a73b-4290-b583-319838bd5305"
      },
      "source": [
        "!pip install transformers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 890kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 890kB 29.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.0MB 45.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.1MB 53.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=23a34b0995ad105282132bf7f0353fe246fabf74009fd656a6a611c27ed868bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2MP5oB0EJ7F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0d420732-63e3-47fa-d969-0317272116b1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FueJ0meBGu1T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "4f639a9f-3cec-4187-8bee-b5bf96f5668a"
      },
      "source": [
        "data = pd.read_csv('gdrive/My Drive/overview-of-recordings.csv')\n",
        "data1 = data[['phrase','prompt']]\n",
        "data1.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase</th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2951</th>\n",
              "      <td>I feel back pain when I carry heavy things</td>\n",
              "      <td>Back pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2758</th>\n",
              "      <td>I feel great pain in the head</td>\n",
              "      <td>Head ache</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1794</th>\n",
              "      <td>There is a tingling sensation in my neck.</td>\n",
              "      <td>Neck pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>I get breakouts on my chest with red patches t...</td>\n",
              "      <td>Acne</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6093</th>\n",
              "      <td>I feel discomfort throughout the body in general</td>\n",
              "      <td>Body feels weak</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 phrase           prompt\n",
              "2951         I feel back pain when I carry heavy things        Back pain\n",
              "2758                      I feel great pain in the head        Head ache\n",
              "1794          There is a tingling sensation in my neck.        Neck pain\n",
              "376   I get breakouts on my chest with red patches t...             Acne\n",
              "6093   I feel discomfort throughout the body in general  Body feels weak"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMQu15Zzt4HI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c129c97c-75ab-4e49-c53c-afeae69e5a5a"
      },
      "source": [
        "df=data1.copy()\n",
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "phrase    0\n",
              "prompt    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E05SMzDrIytN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "be5e6850-c9e9-4462-9cae-8e5ceb83cab5"
      },
      "source": [
        "df['prompt'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Acne                  328\n",
              "Shoulder pain         320\n",
              "Joint pain            318\n",
              "Infected wound        306\n",
              "Knee pain             305\n",
              "Cough                 293\n",
              "Feeling dizzy         283\n",
              "Muscle pain           282\n",
              "Heart hurts           273\n",
              "Ear ache              270\n",
              "Hair falling out      264\n",
              "Head ache             263\n",
              "Feeling cold          263\n",
              "Skin issue            262\n",
              "Stomach ache          261\n",
              "Back pain             259\n",
              "Neck pain             251\n",
              "Internal pain         248\n",
              "Blurry vision         246\n",
              "Body feels weak       241\n",
              "Hard to breath        233\n",
              "Emotional pain        231\n",
              "Injury from sports    230\n",
              "Foot ache             223\n",
              "Open wound            208\n",
              "Name: prompt, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Mgt9PVaFrFl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "641ca72b-6075-494b-82d4-b3ee98b1a035"
      },
      "source": [
        "print('Total number of intents: %d'%(len(df['prompt'].value_counts().index)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of intents: 25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_PN999p9EnS"
      },
      "source": [
        "## 3. Split data to train, validation and test sets\r\n",
        "\r\n",
        "I split data to train(70%), validation(10%) and testset (20%) stratified by the variable \"intent\". After stratification, data for each intent will balanced and data for each set will be proportional to 70%, 10% and 20%. That is crucial for training and testing purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fCzm8IF8JN1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, sentence_test, y, intent_test = train_test_split(df.phrase, df.prompt, stratify = df.prompt,test_size=0.2, random_state=4612)\n",
        "sentence_train, sentence_val, intent_train, intent_val = train_test_split(X, y, stratify = y,test_size=0.125, random_state=4612)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOI6Dy20-hNt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "98218f9a-4400-4162-8049-8dd0b04662c2"
      },
      "source": [
        "print(f\"#examples in training set:{ sentence_train.shape[0]}\\n#examples in validation set:{ sentence_val.shape[0]}\\n#examples in test set:{ sentence_test.shape[0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#examples in training set:4662\n",
            "#examples in validation set:666\n",
            "#examples in test set:1333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI7xNZKGUDeC"
      },
      "source": [
        "## 4. Tokenization and input formatting\n",
        "\n",
        "I Prepare the input data to the correct format before training as follows:\n",
        "* tokenizing all sentences \n",
        "* padding and truncating all sentences to the same length. \n",
        "* Creating the attention masks which explicitly differentiate real tokens from [PAD] tokens. 0 or 1.\n",
        "* encoding the label \"intent\" to numbers. 25 intents to 25 numbers.\n",
        "* creating DataLoaders for our training, validation and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBedRwgVNk0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "be56de9babe442a4811d85b3339548aa",
            "a8e53b37b054446eb76fe87abbddf460",
            "cee66c2d4b384d7a8b7e946718706f71",
            "b81b76652a25465c8bcfbadba860cf79",
            "671bcb82972a4412a16db716011f17a8",
            "aa96b8556db34c94b9e40474c2381e2f",
            "c38251a78d434a73a6dab64dafcad531",
            "8fb32ff00d84494182a9c075983edf2c"
          ]
        },
        "outputId": "4ef216da-dd83-424d-c0cb-cf0f809c7903"
      },
      "source": [
        "# Defining some key variables that will be used later on in the training\n",
        "TRAIN_BATCH_SIZE =32\n",
        "VALID_BATCH_SIZE = 64\n",
        "EPSILON = 1e-08\n",
        "EPOCHS = 4\n",
        "LEARNING_RATE = 2e-5\n",
        "SEED = 1215\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be56de9babe442a4811d85b3339548aa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGyiR6ewfUmR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "af12cf85-0437-4c02-a6c9-74c3c74745cd"
      },
      "source": [
        "max_len = 0\n",
        "input = []\n",
        "length=[]\n",
        "# For every sentence...\n",
        "for sent in sentence_train:\n",
        "\n",
        "    # Tokenize the text and add special tokens--`[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "    input.append(input_ids)\n",
        "    length.append(len(input_ids))\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "    mean_len = sum(length)/len(length)\n",
        "#39 tokens is the maximum number of tokens in a sentence (transcription). Also, a sentence has 14 tokens on average.\n",
        "print('Max sentence length:%d \\nMean sentence length:%d' % (max_len,mean_len))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:39 \n",
            "Mean sentence length:14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmP18btQcDtk"
      },
      "source": [
        "# create a function to tokenize sentences.  \n",
        "def tokenize(sentence):\n",
        "  batch = tokenizer(list(sentence),             \n",
        "                  is_pretokenized=False,\n",
        "                  #Pad or truncate all sentences to the same length. Create the attention masks which explicitly differentiate real tokens from [PAD] tokens.\n",
        "                  padding=True, \n",
        "                  truncation=True,\n",
        "                  return_tensors=\"pt\")\n",
        "  return batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzj1fPMi4trY"
      },
      "source": [
        "tok_train = tokenize(sentence_train)\n",
        "tok_val = tokenize(sentence_val)\n",
        "tok_test = tokenize(sentence_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpUEorEFS9DW"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "# encode \"intent\" to 25 number labels\n",
        "LE = LabelEncoder()\n",
        "label_train = torch.tensor((LE.fit_transform(intent_train)))\n",
        "label_val = torch.tensor((LE.fit_transform(intent_val)))\n",
        "label_test = torch.tensor((LE.fit_transform(intent_test)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7pdk4xI4q79"
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "train_dataset = TensorDataset(tok_train['input_ids'], tok_train['attention_mask'],label_train)\n",
        "validation_dataset = TensorDataset(tok_val['input_ids'], tok_val['attention_mask'],label_val)\n",
        "test_dataset = TensorDataset(tok_test['input_ids'], tok_test['attention_mask'],label_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEas6b_5gdt3"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = TRAIN_BATCH_SIZE # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation/test the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            validation_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(validation_dataset), # Pull out batches sequentially.\n",
        "            batch_size = VALID_BATCH_SIZE # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "            validation_dataset, \n",
        "            sampler = SequentialSampler(validation_dataset), \n",
        "            batch_size = VALID_BATCH_SIZE \n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rgEw1M6SdEh"
      },
      "source": [
        "## 5. Train BERT classification model\r\n",
        "\r\n",
        "I use BertForSequenceClassification, a BERT model with an added single linear layer on top for classification. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES9tG3TtZeKd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "8b9d2f88b57246cf96e9a6c2c89ab718",
            "f9be3136155b4142a063643b614b0dd1",
            "d30bd8a5f8ec48859cd6a0060adf8413",
            "048c8b900b2c476cb650e19e2ef91f48",
            "17e5c0b7d44f45c8b790243b90559409",
            "1bf16755fa3e4a2a82b89b3b3de44b85",
            "6dc92dc6a3a746c2b71fa7376451325e",
            "be3a7b235c7a4a4399a10dd783abc5ca",
            "6d5059f5a143464594775b110e1c7ee0",
            "2a9bda2c09524a87bbd15684e89d799d",
            "2e6558cce2fe490eac8a1d3515a50f6c",
            "5f9a469c8723465aafc26e8a19513cd8",
            "d913a3797b7c4265936a9c7804947049",
            "4bee615ac43d42e984797361b9b3fa9f",
            "de947603ca6c4156b0c4a81f5a9d4bb1",
            "0d334b6fdec9409b902289c6045f50d1"
          ]
        },
        "outputId": "418292ac-dc38-4d93-f864-7fd6733a25ea"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "## use pretained base(relatively small) BERT mdoel for sequence classification \n",
        "#CUDA_LAUNCH_BLOCKING=1\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 25)\n",
        "model.cuda() # make pytorch run this model on GPU.\n",
        "\n",
        "## use AdamW optimizer\n",
        "optimizer = AdamW(model.parameters(), \n",
        "                  lr = LEARNING_RATE, \n",
        "                  eps = EPSILON #very small number to prevent any division by zero )\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "total_steps = len(train_dataloader) * EPOCHS\n",
        "\n",
        "## Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b9d2f88b57246cf96e9a6c2c89ab718",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d5059f5a143464594775b110e1c7ee0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN98ADE7daEY"
      },
      "source": [
        "# Function to calcuate the accuracy of the model\n",
        "\n",
        "def calcuate_accu(big_idx, targets):\n",
        "    n_correct = (big_idx==targets).sum().item()\n",
        "    return n_correct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7vskXYEwOrM"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    #Takes a time in seconds and returns a string hh:mm:ss\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))   \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qr6xDxPmZH8"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs/Tensorboard')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSf6uUcKe0ak"
      },
      "source": [
        "# Start the training process:\n",
        "import random\n",
        "import torch\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "def train(epochs):\n",
        "  total_t0 = time.time() # Measure the total training time for the whole run.\n",
        "  tr_loss = 0\n",
        "  n_correct = 0\n",
        "  nb_tr_steps = 0\n",
        "  nb_tr_examples = 0\n",
        "  \n",
        "  # For each epoch...\n",
        "  for epoch in range(0, epochs):\n",
        "      print('======== Epoch {:} / {:} ========'.format(epoch + 1, epochs))\n",
        "      print('Training...')\n",
        "\n",
        "      t0 = time.time()     # Measure how long the training epoch takes.\n",
        "      total_tr_loss = 0\n",
        "      total_n_correct = 0\n",
        "      total_nb_tr_examples = 0\n",
        "      model.train()    # Put the model into training mode\n",
        "\n",
        "      # For each batch of training data...\n",
        "      for step, batch in enumerate(train_dataloader, 0):     \n",
        "          # 'batch' contains three pytorch tensors:[0]: input ids, [1]: attention masks, [2]: labels \n",
        "          input_ids = batch[0].to(device, dtype = torch.long)\n",
        "          input_mask = batch[1].to(device, dtype = torch.long)\n",
        "          labels = batch[2].to(device, dtype = torch.long)\n",
        "\n",
        "          model.zero_grad()       #clear any previously calculated gradients \n",
        "\n",
        "          outputs = model(input_ids, token_type_ids=None, attention_mask=input_mask)\n",
        "          loss_function = torch.nn.CrossEntropyLoss()\n",
        "          loss = loss_function(outputs[0], labels) #`loss` is a Tensor containing a single value\n",
        "          tr_loss += loss.item() #.item()` function just returns the Python value from the tensor\n",
        "          total_tr_loss += loss.item()\n",
        "          big_val, big_idx = torch.max(outputs[0], dim=1)\n",
        "          n_correct += calcuate_accu(big_idx, labels)  \n",
        "          total_n_correct += calcuate_accu(big_idx, labels)                  \n",
        "          nb_tr_steps += 1\n",
        "          nb_tr_examples+=labels.size(0)\n",
        "          total_nb_tr_examples+=labels.size(0)\n",
        "\n",
        "          if step % 20==19:\n",
        "              loss_step = tr_loss/nb_tr_steps\n",
        "              accu_step = n_correct/nb_tr_examples # #correct examples/all examples \n",
        "              print(f\"Training Loss per 20 steps(batches): {loss_step}\")\n",
        "              print(f\"Training Accuracy per 20 steps(batches): {accu_step}\")\n",
        "              elapsed = format_time(time.time() - t0)    # Calculate elapsed time in minutes.   \n",
        "              # Report progress.\n",
        "              print('Batch {} of {}.  Elapsed: {:}.'.format(step+1, len(train_dataloader), elapsed))\n",
        "              #writer.add_scalar('training loss', loss_step, (epoch +1)*len(trainloader) )\n",
        "              tr_loss = 0;n_correct = 0;nb_tr_steps = 0;nb_tr_examples = 0\n",
        "                \n",
        "          loss.backward() # Perform a backward pass to calculate the gradients.\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # Clip the norm of the gradients to 1.0. This is to help prevent the \"exploding gradients\" problem.\n",
        "          optimizer.step()\n",
        "          scheduler.step() # Update the learning rate.\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "      train_loss_per_epoch = total_tr_loss / len(train_dataloader)            \n",
        "      train_accuracy_per_epoch=total_n_correct/total_nb_tr_examples\n",
        "      # Measure how long this epoch took.\n",
        "      training_time = format_time(time.time() - t0)\n",
        "\n",
        "      print(\"\")\n",
        "      print(\"training loss per epoch: {0:.2f}\".format(train_loss_per_epoch))\n",
        "      print(\"training accuracy per epoch: {0:.2f}\".format(train_accuracy_per_epoch))\n",
        "      print(\"Training 1 epcoh took: {:}\".format(training_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv7RYg3fPXkJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aa06ad10-991b-4005-cb85-5973298d35b8"
      },
      "source": [
        "train(epochs = EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Training Loss per 20 steps(batches): 3.207607901096344\n",
            "Training Accuracy per 20 steps(batches): 0.0671875\n",
            "Batch 20 of 146.  Elapsed: 0:00:05.\n",
            "Training Loss per 20 steps(batches): 3.1109325170516966\n",
            "Training Accuracy per 20 steps(batches): 0.0859375\n",
            "Batch 40 of 146.  Elapsed: 0:00:09.\n",
            "Training Loss per 20 steps(batches): 2.941100037097931\n",
            "Training Accuracy per 20 steps(batches): 0.1578125\n",
            "Batch 60 of 146.  Elapsed: 0:00:14.\n",
            "Training Loss per 20 steps(batches): 2.7166395783424377\n",
            "Training Accuracy per 20 steps(batches): 0.2734375\n",
            "Batch 80 of 146.  Elapsed: 0:00:18.\n",
            "Training Loss per 20 steps(batches): 2.4430582165718078\n",
            "Training Accuracy per 20 steps(batches): 0.4875\n",
            "Batch 100 of 146.  Elapsed: 0:00:23.\n",
            "Training Loss per 20 steps(batches): 2.191276413202286\n",
            "Training Accuracy per 20 steps(batches): 0.6421875\n",
            "Batch 120 of 146.  Elapsed: 0:00:27.\n",
            "Training Loss per 20 steps(batches): 1.9297438085079193\n",
            "Training Accuracy per 20 steps(batches): 0.75625\n",
            "Batch 140 of 146.  Elapsed: 0:00:32.\n",
            "\n",
            "training loss per epoch: 2.61\n",
            "training accuracy per epoch: 0.37\n",
            "Training 1 epcoh took: 0:00:33\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Training Loss per 20 steps(batches): 1.5861441722282996\n",
            "Training Accuracy per 20 steps(batches): 0.8625304136253041\n",
            "Batch 20 of 146.  Elapsed: 0:00:04.\n",
            "Training Loss per 20 steps(batches): 1.3843166470527648\n",
            "Training Accuracy per 20 steps(batches): 0.865625\n",
            "Batch 40 of 146.  Elapsed: 0:00:09.\n",
            "Training Loss per 20 steps(batches): 1.14256412088871\n",
            "Training Accuracy per 20 steps(batches): 0.925\n",
            "Batch 60 of 146.  Elapsed: 0:00:14.\n",
            "Training Loss per 20 steps(batches): 0.9932358473539352\n",
            "Training Accuracy per 20 steps(batches): 0.9359375\n",
            "Batch 80 of 146.  Elapsed: 0:00:18.\n",
            "Training Loss per 20 steps(batches): 0.8442562162876129\n",
            "Training Accuracy per 20 steps(batches): 0.9625\n",
            "Batch 100 of 146.  Elapsed: 0:00:23.\n",
            "Training Loss per 20 steps(batches): 0.6967461615800857\n",
            "Training Accuracy per 20 steps(batches): 0.9703125\n",
            "Batch 120 of 146.  Elapsed: 0:00:27.\n",
            "Training Loss per 20 steps(batches): 0.6236915081739426\n",
            "Training Accuracy per 20 steps(batches): 0.9765625\n",
            "Batch 140 of 146.  Elapsed: 0:00:32.\n",
            "\n",
            "training loss per epoch: 1.01\n",
            "training accuracy per epoch: 0.93\n",
            "Training 1 epcoh took: 0:00:34\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Training Loss per 20 steps(batches): 0.5283277688118128\n",
            "Training Accuracy per 20 steps(batches): 0.9829683698296837\n",
            "Batch 20 of 146.  Elapsed: 0:00:05.\n",
            "Training Loss per 20 steps(batches): 0.43248309642076493\n",
            "Training Accuracy per 20 steps(batches): 0.990625\n",
            "Batch 40 of 146.  Elapsed: 0:00:09.\n",
            "Training Loss per 20 steps(batches): 0.4051169976592064\n",
            "Training Accuracy per 20 steps(batches): 0.9828125\n",
            "Batch 60 of 146.  Elapsed: 0:00:14.\n",
            "Training Loss per 20 steps(batches): 0.3535314604640007\n",
            "Training Accuracy per 20 steps(batches): 0.984375\n",
            "Batch 80 of 146.  Elapsed: 0:00:19.\n",
            "Training Loss per 20 steps(batches): 0.31365336030721663\n",
            "Training Accuracy per 20 steps(batches): 0.9921875\n",
            "Batch 100 of 146.  Elapsed: 0:00:23.\n",
            "Training Loss per 20 steps(batches): 0.27215839698910715\n",
            "Training Accuracy per 20 steps(batches): 0.996875\n",
            "Batch 120 of 146.  Elapsed: 0:00:28.\n",
            "Training Loss per 20 steps(batches): 0.2572125673294067\n",
            "Training Accuracy per 20 steps(batches): 0.9921875\n",
            "Batch 140 of 146.  Elapsed: 0:00:33.\n",
            "\n",
            "training loss per epoch: 0.36\n",
            "training accuracy per epoch: 0.99\n",
            "Training 1 epcoh took: 0:00:34\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Training Loss per 20 steps(batches): 0.23088697630625504\n",
            "Training Accuracy per 20 steps(batches): 0.9987834549878345\n",
            "Batch 20 of 146.  Elapsed: 0:00:05.\n",
            "Training Loss per 20 steps(batches): 0.20307304486632347\n",
            "Training Accuracy per 20 steps(batches): 0.9984375\n",
            "Batch 40 of 146.  Elapsed: 0:00:09.\n",
            "Training Loss per 20 steps(batches): 0.19804720655083657\n",
            "Training Accuracy per 20 steps(batches): 0.9953125\n",
            "Batch 60 of 146.  Elapsed: 0:00:14.\n",
            "Training Loss per 20 steps(batches): 0.19199633449316025\n",
            "Training Accuracy per 20 steps(batches): 0.996875\n",
            "Batch 80 of 146.  Elapsed: 0:00:19.\n",
            "Training Loss per 20 steps(batches): 0.17527931705117225\n",
            "Training Accuracy per 20 steps(batches): 0.996875\n",
            "Batch 100 of 146.  Elapsed: 0:00:24.\n",
            "Training Loss per 20 steps(batches): 0.17845937386155128\n",
            "Training Accuracy per 20 steps(batches): 0.9953125\n",
            "Batch 120 of 146.  Elapsed: 0:00:28.\n",
            "Training Loss per 20 steps(batches): 0.19288426265120506\n",
            "Training Accuracy per 20 steps(batches): 0.990625\n",
            "Batch 140 of 146.  Elapsed: 0:00:33.\n",
            "\n",
            "training loss per epoch: 0.19\n",
            "training accuracy per epoch: 1.00\n",
            "Training 1 epcoh took: 0:00:35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0GRYwY0dTs9"
      },
      "source": [
        "## 6. Test the model on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlTEWtXojLWy"
      },
      "source": [
        "# test the model on the validation set\n",
        "def valid(model, validation_loader):\n",
        "  model.eval()\n",
        "  val_loss = 0\n",
        "  nb_val_examples = 0\n",
        "  n_correct = 0\n",
        "  with torch.no_grad():\n",
        "    for _, data in enumerate(validation_loader, 0): \n",
        "      ids = data[0].to(device, dtype = torch.long)\n",
        "      mask = data[1].to(device, dtype = torch.long)\n",
        "      targets = data[2].to(device, dtype = torch.long)\n",
        "      outputs = model(ids, mask)\n",
        "      loss_function = torch.nn.CrossEntropyLoss()\n",
        "      loss = loss_function(outputs[0], targets)\n",
        "      val_loss += loss.item()\n",
        "      big_val, big_idx = torch.max(outputs[0], dim=1)\n",
        "      n_correct += calcuate_accu(big_idx, targets)\n",
        "      nb_val_examples+=targets.size(0)\n",
        "\n",
        "  val_ave_loss = val_loss/len(validation_loader)\n",
        "  val_accu = (n_correct*100)/nb_val_examples\n",
        "  print(\"Loss on validation/test data: %0.2f\" % val_ave_loss)\n",
        "  print(\"Accuracy on validation/test data: %0.2f%%\" % val_accu)\n",
        "  \n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_zvJtc8jzUf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3d04543b-6c07-4760-ecee-3bf589b2cddf"
      },
      "source": [
        "valid(model, validation_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss on validation/test data: 0.14\n",
            "Accuracy on validation/test data: 99.40%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kbEq1nfdlTS"
      },
      "source": [
        "## 7. Obtain test error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veyLRX0X7F34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e4bf7f26-4f2c-4597-e3d9-9fe9f0d9debd"
      },
      "source": [
        "valid(model, test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss on validation/test data: 0.14\n",
            "Accuracy on validation/test data: 99.40%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXuYH1QzdxCq"
      },
      "source": [
        "## 8. Save the model, tokenizer and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgJ1ZiFbOv-G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "ab7a2118-5aab-4cef-ec37-5c6f1884a987"
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './Documents/intent_detection_healthcare_bert/saved_bert_model_and_tokenizer/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "  os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./Documents/intent_detection_healthcare_bert/saved_bert_model_and_tokenizer/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./Documents/intent_detection_healthcare_bert/saved_bert_model_and_tokenizer/vocab.txt',\n",
              " './Documents/intent_detection_healthcare_bert/saved_bert_model_and_tokenizer/special_tokens_map.json',\n",
              " './Documents/intent_detection_healthcare_bert/saved_bert_model_and_tokenizer/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isbt1ZKiGc6U"
      },
      "source": [
        "df_label = pd.DataFrame(tuple(zip(range(25),LE.classes_)), columns=['id','intent'])\n",
        "df_label.to_pickle('./Documents/intent_detection_healthcare_bert/saved_bert_model_and_tokenizer/df_label.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDBt5d0vSxjG"
      },
      "source": [
        "# Copy the model files to a directory in Google Drive.\n",
        "!cp -r ./Documents/intent_detection_healthcare_bert/saved_bert_model_and_tokenizer/ \"gdrive/My Drive/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8LixoWUeaz_"
      },
      "source": [
        "## 9. Prepare the model for deployment\r\n",
        "* Load the saved model, tokenizer and labels \r\n",
        "* Create a medical_symptom_detector function with the loaded model, tokenizer and labels, which helps predict the medical intent of a medical message. \r\n",
        "* test the detector on an unseen example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XakLziFwLyZ5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "0dd6757e-c2aa-470a-8155-16601aecb5c3"
      },
      "source": [
        "#### load the model and build the detector for deployment\n",
        "!pip install transformers\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "input_dir = 'gdrive/My Drive/saved_bert_model_and_tokenizer/'\n",
        "\n",
        "loaded_model = BertForSequenceClassification.from_pretrained(input_dir)\n",
        "loaded_model.eval()\n",
        "loaded_tokenizer = BertTokenizer.from_pretrained(input_dir)\n",
        "loaded_df_label = pd.read_pickle('gdrive/My Drive/saved_bert_model_and_tokenizer/df_label.pkl')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrAUw6PmVyoo"
      },
      "source": [
        "# test the model on an unseen example\n",
        "\n",
        "def medical_symptom_detector(intent):\n",
        "\n",
        "  pt_batch = loaded_tokenizer(\n",
        "  intent,\n",
        "  padding=True,\n",
        "  truncation=True,\n",
        "  return_tensors=\"pt\")\n",
        "\n",
        "  pt_outputs = loaded_model(**pt_batch)\n",
        "  __, id = torch.max(pt_outputs[0], dim=1)\n",
        "  prediction = loaded_df_label.iloc[[id.item()]]['intent'].item()\n",
        "  print('You may have a medical condition: %s. Would you like me to transfer your call to your doctor?'%(prediction))\n",
        "  return "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6XsSWSTHz5C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a8629dab-c6eb-4774-d153-ff04f3144f5f"
      },
      "source": [
        "input = 'my left knee hurts so much'\n",
        "medical_symptom_detector(input)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You may have a medical condition: Knee pain. Would you like me to transfer your call to your doctor?\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}